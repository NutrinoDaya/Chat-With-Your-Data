services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_storage:/qdrant/storage
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 10s
      timeout: 5s
      retries: 3

  vllm:
    build:
      context: ./backend
      dockerfile: Dockerfile.vllm
    container_name: vllm-server
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    ports:
      - "8000:8000"
    environment:
      - HF_TOKEN=${HF_TOKEN}
      - TRANSFORMERS_CACHE=/root/.cache/huggingface
    volumes:
      - model_cache:/root/.cache/huggingface
    command: [
      "--model", "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
      "--gpu-memory-utilization", "0.6",
      "--port", "8000",
      "--host", "0.0.0.0",
      "--max-model-len", "2048",
      "--dtype", "float16"
    ]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.backend
    ports:
      - "8001:8001"
    environment:
      - VLLM_SERVICE_URL=http://vllm:8000
      - TRANSFORMERS_CACHE=/root/.cache/huggingface
      - PYTHONPATH=/app
    volumes:
      - ./backend/src:/app/src
      - ./backend/config:/app/config
      - ./backend/scripts:/app/scripts
      - backend_data:/app/data
      - backend_charts:/app/charts
      - model_cache:/root/.cache/huggingface
    depends_on:
      - vllm
      - redis
      - qdrant
    restart: unless-stopped

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.frontend
    ports:
      - "5173:5173"
    depends_on:
      - backend
    restart: unless-stopped

volumes:
  qdrant_storage:
  backend_data:
  backend_charts:
  redis_data:
  model_cache:

networks:
  default:
    name: chat-with-data-network
